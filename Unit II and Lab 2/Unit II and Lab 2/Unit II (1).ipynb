{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7590bfc",
   "metadata": {},
   "source": [
    "UNIT II: Data Analysis:\n",
    "Lecture 1: Introduction to Data Understanding and Pre-processing\n",
    "Lecture 2: Knowledge domains of Data Analysis,Understanding structured and unstructured data\n",
    "Lecture 3: Data Analysis process, Dataset generation\n",
    "Lecture 4: Importing Dataset: Importing and Exporting Data, Basic Insights from Datasets\n",
    "Lecture 5: Cleaning and Preparing the Data: Identify and Handle Missing Values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9a8ce",
   "metadata": {},
   "source": [
    "Lecture 4: Importing Dataset: Importing and Exporting Data, Basic Insights from Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e52ef1",
   "metadata": {},
   "source": [
    "1. Getting/Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3097e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     App             Category  \\\n",
      "0         Photo Editor & Candy Camera & Grid & ScrapBook       ART_AND_DESIGN   \n",
      "1                                    Coloring book moana       ART_AND_DESIGN   \n",
      "2      U Launcher Lite – FREE Live Cool Themes, Hide ...       ART_AND_DESIGN   \n",
      "3                                  Sketch - Draw & Paint       ART_AND_DESIGN   \n",
      "4                  Pixel Draw - Number Art Coloring Book       ART_AND_DESIGN   \n",
      "...                                                  ...                  ...   \n",
      "10836                                   Sya9a Maroc - FR               FAMILY   \n",
      "10837                   Fr. Mike Schmitz Audio Teachings               FAMILY   \n",
      "10838                             Parkinson Exercices FR              MEDICAL   \n",
      "10839                      The SCP Foundation DB fr nn5n  BOOKS_AND_REFERENCE   \n",
      "10840      iHoroscope - 2018 Daily Horoscope & Astrology            LIFESTYLE   \n",
      "\n",
      "       Rating Reviews                Size     Installs  Type Price  \\\n",
      "0         4.1     159                 19M      10,000+  Free     0   \n",
      "1         3.9     967                 14M     500,000+  Free     0   \n",
      "2         4.7   87510                8.7M   5,000,000+  Free     0   \n",
      "3         4.5  215644                 25M  50,000,000+  Free     0   \n",
      "4         4.3     967                2.8M     100,000+  Free     0   \n",
      "...       ...     ...                 ...          ...   ...   ...   \n",
      "10836     4.5      38                 53M       5,000+  Free     0   \n",
      "10837     5.0       4                3.6M         100+  Free     0   \n",
      "10838     NaN       3                9.5M       1,000+  Free     0   \n",
      "10839     4.5     114  Varies with device       1,000+  Free     0   \n",
      "10840     4.5  398307                 19M  10,000,000+  Free     0   \n",
      "\n",
      "      Content Rating                     Genres      Last Updated  \\\n",
      "0           Everyone               Art & Design   January 7, 2018   \n",
      "1           Everyone  Art & Design;Pretend Play  January 15, 2018   \n",
      "2           Everyone               Art & Design    August 1, 2018   \n",
      "3               Teen               Art & Design      June 8, 2018   \n",
      "4           Everyone    Art & Design;Creativity     June 20, 2018   \n",
      "...              ...                        ...               ...   \n",
      "10836       Everyone                  Education     July 25, 2017   \n",
      "10837       Everyone                  Education      July 6, 2018   \n",
      "10838       Everyone                    Medical  January 20, 2017   \n",
      "10839     Mature 17+          Books & Reference  January 19, 2015   \n",
      "10840       Everyone                  Lifestyle     July 25, 2018   \n",
      "\n",
      "              Current Ver         Android Ver  \n",
      "0                   1.0.0        4.0.3 and up  \n",
      "1                   2.0.0        4.0.3 and up  \n",
      "2                   1.2.4        4.0.3 and up  \n",
      "3      Varies with device          4.2 and up  \n",
      "4                     1.1          4.4 and up  \n",
      "...                   ...                 ...  \n",
      "10836                1.48          4.1 and up  \n",
      "10837                 1.0          4.1 and up  \n",
      "10838                 1.0          2.2 and up  \n",
      "10839  Varies with device  Varies with device  \n",
      "10840  Varies with device  Varies with device  \n",
      "\n",
      "[10841 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "#print(data.isnull().sum())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68014af4",
   "metadata": {},
   "source": [
    "2. Exporting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e0206",
   "metadata": {},
   "source": [
    "When you are done with the data manipulation or generated prediction for some input data,\n",
    "you will want to save the data as a file, so that, you can share it with others.\n",
    "The most common format is a csv file or excel file.\n",
    "\n",
    "The built in functions to_csv() and to_excel() of a pandas DataFrame can be used in \n",
    "order to export data as a csv or excel file.\n",
    "\n",
    "df.to_csv(r'Path where you want to store the exported CSV file\\File Name.csv')\n",
    "\n",
    "The difference between CSV and XLS file formats is that CSV format is a plain text format\n",
    "in which values are separated by commas (Comma Separated Values), while XLS file format\n",
    "is an Excel Sheets binary file format which holds information about all the worksheets\n",
    "in a file, including both content and formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc44317",
   "metadata": {},
   "source": [
    "DataFrame is a 2-dimensional labeled data structure with columns of potentially\n",
    "different types. You can think of it like a spreadsheet or SQL table, or a dict\n",
    "of Series objects. It is generally the most commonly used pandas object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd8262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Col1    Col2\n",
      "0    10  value1\n",
      "1    20  value2\n",
      "2    30  value3\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "DataSample= [[10,'value1'], \n",
    "             [20,'value2'], \n",
    "             [30,'value3']]\n",
    "SimpleDataFrame=pd.DataFrame(data=DataSample, columns=['Col1','Col2'])\n",
    "#SimpleDataFrame=SimpleDataFrame.reset_index(drop=True)\n",
    "print(SimpleDataFrame)\n",
    "# Exporting data frame to a csv/Excel file\n",
    "# Many other options are available which can be seen using dot tab option\n",
    "\n",
    "# Exporting data as a csv file\n",
    "SimpleDataFrame.to_csv(\"C:/Users/Faculty-34/Desktop/Export.csv\")\n",
    "\n",
    "# Exporting data as a excel file\n",
    "SimpleDataFrame.to_excel(\"C:/Users/Faculty-34/Documents/Export2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c373f2",
   "metadata": {},
   "source": [
    "Data preprocessing is a process of preparing the raw data and making it suitable for a machine learning model.\n",
    "It is the first and crucial step while creating a machine learning model.\n",
    "When creating a machine learning project, it is not always a case that we come across the clean and formatted data.\n",
    "And while doing any operation with data, it is mandatory to clean it and put in a formatted way.\n",
    "So for this, we use data preprocessing task.\n",
    "\n",
    "Why do we need Data Preprocessing?\n",
    "A real-world data generally contains noises, missing values, and maybe in an unusable format\n",
    "which cannot be directly used for machine learning models.\n",
    "Data preprocessing is required tasks for cleaning the data and making it suitable for a\n",
    "machine learning model which also increases the accuracy and efficiency of a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4dbf90",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2870682692.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Faculty-34\\AppData\\Local\\Temp\\ipykernel_34808\\2870682692.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Some Important Libraries:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Some Important Libraries:\n",
    "Numpy\n",
    "Matplotlib\n",
    "Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e710d",
   "metadata": {},
   "source": [
    "1. Numpy:\n",
    "Numpy Python library is used for including any type of\n",
    "mathematical operation in the code. It is the fundamental package\n",
    "for scientific calculation in Python. It also supports to add large,\n",
    "multidimensional arrays and matrices.\n",
    "So, in Python, we can import it as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db965a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e114b",
   "metadata": {},
   "source": [
    "2. Matplotlib:\n",
    "The second library is matplotlib, which is a Python 2D plotting library,\n",
    "and with this library, we need to import a sub-library pyplot. This library is\n",
    "used to plot any type of charts in Python for the code.\n",
    "It will be imported as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85771291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5780eb",
   "metadata": {},
   "source": [
    "3. Pandas:\n",
    "The last library is the Pandas library, which is one of the most\n",
    "famous Python libraries and used for importing and managing the datasets.\n",
    "It is an open-source data manipulation and analysis library.\n",
    "It will be imported as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0397369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lecture 5: Cleaning and Preparing the Data: Identify and Handle Missing Values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782a208",
   "metadata": {},
   "source": [
    "1. Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e09397",
   "metadata": {},
   "source": [
    "Identifying and Handling Missing or Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ddd840",
   "metadata": {},
   "source": [
    "While making a Data Frame from a csv file, many blank columns are imported\n",
    "as null value into the Data Frame which later creates problems while operating that data frame.\n",
    "\n",
    "Pandas isnull() and notnull() methods are used to check and manage NULL values in a data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3705e",
   "metadata": {},
   "source": [
    "DataFrame is a 2-dimensional labeled data structure with columns of\n",
    "potentially different types. You can think of it like a spreadsheet\n",
    "or SQL table, or a dict of Series objects. It is generally the most\n",
    "commonly used pandas object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f034b0c",
   "metadata": {},
   "source": [
    "Dataframe.isnull()\n",
    "\n",
    "Syntax: Pandas.isnull(“DataFrame Name”) or DataFrame.isnull()\n",
    "Parameters: Object to check null values for\n",
    "Return Type: Dataframe of Boolean values which are True for NaN values \n",
    " \n",
    "\n",
    "If we add the sum function after the isnull() it will give us the total number\n",
    "of data which are not present or null in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "print(data.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa4d594",
   "metadata": {},
   "source": [
    "Use the any() method that returns True if there is at least one True in each row/column.\n",
    "By default, it is applied to columns. If axis=1, it is applied to rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a436b2",
   "metadata": {},
   "source": [
    "By calling any() from the result of isnull(), you can check if \n",
    "each row and column contains at least one missing value.\n",
    "\n",
    "Extract rows that contain at least one missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f726d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "print(data.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd91f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "print(data[data.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract columns that contain at least one missing value:\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "print(data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d94bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "print(data.loc[:, data.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "print(data.loc[:, data.isnull().any()])\n",
    "print(data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "#number of missing values in each column\n",
    "print(data.isnull().sum())\n",
    "#percentage of missing values\n",
    "data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d3cc3",
   "metadata": {},
   "source": [
    "So we can see that our columns are App, Category, Rating etc.\n",
    "So the number which is being displayed after the column names\n",
    "is basically the total number of null values that particular column is containing.\n",
    "\n",
    "\n",
    "So we can delete all the rows which are present in our dataframe with the help\n",
    "of dropna() function. Let us see the implementation of that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad88a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna()\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "So no more null values are present in any of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cff394",
   "metadata": {},
   "source": [
    "Basic Insights from the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31594b82",
   "metadata": {},
   "source": [
    "We have already seen how we could remove the null values from our dataset.\n",
    "Let us analyse the numeric data present with us and try to find out the inferences which we can get.\n",
    "So let us see our dataset again before getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04612b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2c0d7",
   "metadata": {},
   "source": [
    "Let us do some analysis on the Rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da08592",
   "metadata": {},
   "source": [
    "So the data type of the Rating is float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['App'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64cad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finding out the average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "for i in df['Rating']:\n",
    "    s+=i\n",
    "s=int(s)\n",
    "a=s/len(df['Rating'])\n",
    "print(\"The average Rating of the datas in our data set is : \",round(a,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1b6a6",
   "metadata": {},
   "source": [
    "How many apps are there with rating 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in df['Rating']:\n",
    "    if (i==5.0):\n",
    "        c+=1\n",
    "print(f\"There are {c} applications with rating 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba0ebd",
   "metadata": {},
   "source": [
    "Apps with Rating between the range of 4 and 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad623e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in df['Rating']:\n",
    "    if (i>=4.0 and i<=4.5):\n",
    "        c+=1\n",
    "print(f\"There are {c} applications with rating between the range of 4 and 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc05ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "We have already done some analysis on numerical data.\n",
    "Let us work with Categorical data now. \n",
    "Before doing analysis let us see our dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7930ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('googleplaystore.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0901b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total Number of Unique Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950233ec",
   "metadata": {},
   "source": [
    "We can use the unique() function to get all the unique values of Category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "To get the total number of Unique values we can use the nunique() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4baf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=df['Category'].nunique()\n",
    "print(\"There are a total of \",n,\" unique values in Category columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total Number of apps in ART_AND_DESIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd759cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in df['Category']:\n",
    "    if(i=='ART_AND_DESIGN'):\n",
    "        c+=1\n",
    "print(f\"There are a total of {c} applications in ART_AND_DESIGN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4efb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total number of Free and Paid Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=0\n",
    "p=0\n",
    "for i in df['Type']:\n",
    "    if(i=='Free'):\n",
    "        f+=1\n",
    "for i in df['Type']:\n",
    "    if(i=='Paid'):\n",
    "        p+=1\n",
    "print(f\"There are a total number of {f} free and {p} paid apps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percentage of Free and Paid Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=f/len(df['Type'])*100\n",
    "ff=round(ff,2)\n",
    "pp=100-ff\n",
    "pp=round(pp,2)\n",
    "print(f\"A total of {ff}% of the apps are Free and {pp}% of the apps are paid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a9d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Analysis - Automatic Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let us see now how we would automate our categorical data.\n",
    "Firstly let us see our dataset and then we can start with the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('googleplaystore.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54056f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total number of apps in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2835253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "\n",
    "for name in df['Category'].unique():\n",
    "    ct = 0\n",
    "    for i in df['Category']:\n",
    "        if(i == name):\n",
    "            ct += 1\n",
    "    categories[name] = ct\n",
    "    \n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "So we now know now each and every category is containing how many apps in our dataset with the help of this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total number of apps in each Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c848f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {}\n",
    "\n",
    "for name in df['Type'].unique():\n",
    "    ct = 0\n",
    "    for i in df['Type']:\n",
    "        if(i == name):\n",
    "            ct += 1\n",
    "    types[name] = ct\n",
    "    \n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6781188",
   "metadata": {},
   "outputs": [],
   "source": [
    "So there are a total of 10039 Free apps and 800 Paid apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total number of apps in each Content Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf751f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_rating = {}\n",
    "\n",
    "for name in df['Content Rating'].unique():\n",
    "    ct = 0\n",
    "    for i in df['Content Rating']:\n",
    "        if(i == name):\n",
    "            ct += 1\n",
    "    content_rating[name] = ct\n",
    "    \n",
    "print(content_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1824e61",
   "metadata": {},
   "source": [
    "Null Values Handling - Numeric\n",
    "\n",
    "Earlier we have discussed an approach to remove nulll values from a dataset.\n",
    "But removing the null values is always not the most optical approach to work on a dataset.\n",
    "Let us see here how we can handle the null values instead of dropping them.\n",
    "\n",
    "\n",
    "Let us import pandas and read the csv file initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9479da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Data.csv')\n",
    "print(df)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "df = df.dropna()\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc348d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "print(df)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ad09a",
   "metadata": {},
   "source": [
    "When dealing with missing values, different alternatives can be applied:\n",
    "\n",
    "1. check the source, for example by contacting the data source to correct the missing values\n",
    "2. drop missing values\n",
    "3. replace the missing value with a value\n",
    "4. leave the missing value as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81dd74",
   "metadata": {},
   "source": [
    "2. Drop missing values\n",
    "Dropping missing values can be one of the following alternatives:\n",
    "1. remove rows having missing values\n",
    "2. remove the whole column containing missing values\n",
    "\n",
    "We can use the dropna() by specifying the axis to be considered.\n",
    "\n",
    "If we set axis = 0 we drop the entire row, if we set axis = 1 we drop the whole column.\n",
    "\n",
    "If we apply the function df.dropna(axis=0) specific rows of the dataset remain.\n",
    "\n",
    "If we apply the function df.dropna(axis=1), only the specific columns remain.\n",
    "\n",
    "However, removed values are not applied to the original dataframe, but only to the result.\n",
    "We can use the argument inplace=True in order to store changes in the original dataframe.\n",
    "\n",
    "When inplace = True , the data is modified in place, which means it will\n",
    "return nothing and the dataframe is now updated. When inplace = False , \n",
    "which is the default, then the operation is performed and it returns\n",
    "a copy of the object.\n",
    "\n",
    "The inplace parameter enables you to modify your dataframe directly. Remember: by default, the drop() method produces a new dataframe and leaves the original dataframe unchanged. That's because by default, the inplace parameter is set to inplace = False .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ae1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "df.dropna(axis=1,inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa005100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0       Yes\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2      NaN  30.0  54000.0       NaN\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "df.dropna(axis=1,inplace=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a34654d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1548b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "As an alternative, we can specify only the column on which the dropping operation must be applied.\n",
    "In the following example, only missing rows related to the column age are considered.\n",
    "This can be achieved through the subset parameter, which permits to specify the subset\n",
    "of columns where to apply the dropping operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5802361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0       Yes\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2      NaN  30.0  54000.0       NaN\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "df.dropna(subset=['Age'],axis=0,inplace=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebaceaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country      10.0\n",
       "Age          10.0\n",
       "Salary       10.0\n",
       "Purchased    10.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e098a",
   "metadata": {},
   "source": [
    "Another alternative involves the dropping of columns where a certain percentage of\n",
    "not-null values is available. This can be achieved through the thresh parameter.\n",
    "In the following example we keep only columns where there are at least the 80% of not null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fec7d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0       Yes\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2      NaN  30.0  54000.0       NaN\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "#df.dropna(subset=['Age'],axis=0,inplace=True)\n",
    "#print(df)\n",
    "df.dropna(thresh=0.90*len(df),axis=1, inplace=False)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcd738f",
   "metadata": {},
   "source": [
    "So we can see we dont have a big dataset and there are NaN or null values present in almost every column.\n",
    "So now how would we handle them?\n",
    "\n",
    "SimpleImputer is a scikit-learn class which is helpful in handling the missing data\n",
    "in the predictive model dataset. It replaces the NaN values with a specified placeholder.\n",
    "\n",
    "\n",
    "Scikit-learn is an open source data analysis library, and the gold standard\n",
    "for Machine Learning (ML) in the Python ecosystem. Key concepts and features\n",
    "include: Algorithmic decision-making methods, including: Classification:\n",
    "identifying and categorizing data based on patterns.\n",
    "\n",
    "\n",
    "It is implemented by the use of the SimpleImputer() method which takes the following arguments :\n",
    "    \n",
    "missing_values : The missing_values placeholder which has to be imputed. By default is NaN\n",
    "\n",
    "strategy : The data which will replace the NaN values from the dataset\n",
    "The strategy argument can take the values – ‘mean'(default), ‘median’, ‘most_frequent’ and ‘constant’.\n",
    "\n",
    "fill_value : The constant value to be given to the NaN data using the constant strategy.\n",
    "\n",
    "The SimpleImputer class provides basic strategies for imputing missing values.\n",
    "Missing values can be imputed with a provided constant value, or using the\n",
    "statistics (mean, median or most frequent) of each column in which the missing\n",
    "values are located. This class also allows for different missing values encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8592f6",
   "metadata": {},
   "source": [
    "3. Replace missing values\n",
    "A good strategy when dealing with missing values involves their replacement with another value.\n",
    "Usually, the following strategies are adopted:\n",
    "1. For numerical values replace the missing value with the average value of the column\n",
    "2. For categorial values replace the missing value with the most frequent value of the column\n",
    "3. Use other functions\n",
    "In order to replace missing values, three functions can be used: fillna(), replace() and interpolate().\n",
    "1. The fillna() function replaces all the NaN values with the value passed as argument. For example, for numerical values, all the NaN values in the numeric columns could be replaced with the average value.\n",
    "\n",
    "In order to list the type of a column, we can use the attribute dtypes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce841e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country       object\n",
       "Age          float64\n",
       "Salary       float64\n",
       "Purchased     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be3c7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0      Aus  44.0  72000.0       Yes\n",
      "1      Aus  27.0  48000.0       Yes\n",
      "2      NaN  30.0  54000.0       NaN\n",
      "3      Aus  38.0  61000.0        No\n",
      "4      Aus  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6   France   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.777778</td>\n",
       "      <td>63777.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.693793</td>\n",
       "      <td>12265.579662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>61000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>72000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age        Salary\n",
       "count   9.000000      9.000000\n",
       "mean   38.777778  63777.777778\n",
       "std     7.693793  12265.579662\n",
       "min    27.000000  48000.000000\n",
       "25%    35.000000  54000.000000\n",
       "50%    38.000000  61000.000000\n",
       "75%    44.000000  72000.000000\n",
       "max    50.000000  83000.000000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65875ec1",
   "metadata": {},
   "source": [
    "Numeric columns\n",
    "Firstly, we select numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "932f1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numeric = df.select_dtypes(include=np.number)\n",
    "numeric_columns = numeric.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d4d10",
   "metadata": {},
   "source": [
    "Then, we fill the NaN values of numeric columns with the average value, given by the df.mean() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1df2190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty-34\\AppData\\Local\\Temp\\ipykernel_34808\\3464485706.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df[numeric_columns] = df[numeric_columns].fillna(df.mean())\n"
     ]
    }
   ],
   "source": [
    "df[numeric_columns] = df[numeric_columns].fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, we can check whether the NaN values in numeric columns have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a842271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country      10.0\n",
       "Age           0.0\n",
       "Salary        0.0\n",
       "Purchased    10.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30135609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country        Age        Salary Purchased\n",
      "0   France  44.000000  72000.000000       Yes\n",
      "1    Spain  27.000000  48000.000000       Yes\n",
      "2      NaN  30.000000  54000.000000       NaN\n",
      "3    Spain  38.000000  61000.000000        No\n",
      "4  Germany  40.000000  63777.777778       Yes\n",
      "5   France  35.000000  58000.000000       Yes\n",
      "6    Spain  38.777778  52000.000000        No\n",
      "7   France  48.000000  79000.000000       Yes\n",
      "8  Germany  50.000000  83000.000000        No\n",
      "9   France  37.000000  67000.000000       Yes\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46319e21",
   "metadata": {},
   "source": [
    "Categorial columns:\n",
    "We note that in dtypes the categorial columns are described as objects.\n",
    "Thus we can select the object columns. We would like to consider only boolean columns.\n",
    "However the object type includes also the column class, which is a string.\n",
    "We select all the object columns, and then we remove from them the column class.\n",
    "Then we can convert the type of the result to bool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41dd79c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country Purchased\n",
      "0      Aus       Yes\n",
      "1      Aus       Yes\n",
      "2      Aus       Yes\n",
      "3      Aus        No\n",
      "4      Aus       Yes\n",
      "5   France       Yes\n",
      "6   France        No\n",
      "7   France       Yes\n",
      "8  Germany        No\n",
      "9   France       Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty-34\\AppData\\Local\\Temp\\ipykernel_34808\\1465001960.py:4: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  boolean_columns = df.select_dtypes(include=np.object).columns.tolist()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "boolean_columns = df.select_dtypes(include=np.object).columns.tolist()\n",
    "df[boolean_columns]=df[boolean_columns].fillna(df.mode().iloc[0])\n",
    "#result = df.fillna(df.mode().iloc[0])\n",
    "print(df[boolean_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111c84e",
   "metadata": {},
   "source": [
    "Now we can replace all the missing values for booleans with the most frequent value.\n",
    "We can use the mode() function to calculate the most frequent value.\n",
    "We use the fillna() function to replace missing values, but we could use also the\n",
    "replace(old_value,new_value) function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0415f2",
   "metadata": {},
   "source": [
    "Now our dataset does not contain any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26bc8fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country       0.0\n",
       "Age          10.0\n",
       "Salary       10.0\n",
       "Purchased     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "552a33e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0      Aus  44.0  72000.0       Yes\n",
      "1      Aus  27.0  48000.0       Yes\n",
      "2      Aus  30.0  54000.0       Yes\n",
      "3      Aus  38.0  61000.0        No\n",
      "4      Aus  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6   France   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056ff65",
   "metadata": {},
   "source": [
    "3. Interpolation\n",
    "Another solution to replace missing values involves the usage of other functions,\n",
    "such as linear interpolation. In this case, for example, we could replace a missing\n",
    "value over a column, with the interpolation between the previous and the next ones.\n",
    "This can be achieved through the use of the interpolate() function.\n",
    "\n",
    "Since we have already managed all the missing values, we reload the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb789758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aus</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aus</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aus</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aus</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0      Aus  44.0  72000.0       Yes\n",
       "1      Aus  27.0  48000.0       Yes\n",
       "2      NaN  30.0  54000.0       NaN\n",
       "3      Aus  38.0  61000.0        No\n",
       "4      Aus  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6   France   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "#df.dropna(subset=['Age'],axis=0,inplace=True)\n",
    "#print(df)\n",
    "#df.isna().sum()/len(df)*100\n",
    "#We select only numeric columns.\n",
    "numeric = df.select_dtypes(include=np.number)\n",
    "numeric_columns = numeric.columns\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c97ad",
   "metadata": {},
   "source": [
    "Now we can apply the interpolate() function to numeric columns, by setting also the\n",
    "limit direction to forward. This means that the linear interpolation is applied starting\n",
    "from the first row until the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86d42511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric_columns]=df[numeric_columns].interpolate(method ='linear', limit_direction ='forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290b2b6",
   "metadata": {},
   "source": [
    "For example, in line 6 in the column age, which was NaN before the interpolation,\n",
    "now assumes the value 41.5, which is the interpolation between 35.0 (line 5) and 48.5 (line 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee031b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aus</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aus</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aus</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aus</td>\n",
       "      <td>40.0</td>\n",
       "      <td>59500.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>France</td>\n",
       "      <td>41.5</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0      Aus  44.0  72000.0       Yes\n",
       "1      Aus  27.0  48000.0       Yes\n",
       "2      NaN  30.0  54000.0       NaN\n",
       "3      Aus  38.0  61000.0        No\n",
       "4      Aus  40.0  59500.0       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6   France  41.5  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9ba83",
   "metadata": {},
   "source": [
    "# Summary\n",
    "We have seen one of the aspects of data preprocessing, which is dealing with missing data.\n",
    "Missing data can alter the data analysis process, thus they must be managed.\n",
    "Three strategies can be used to deal with missing data:\n",
    "1. drop missing data: this can be done when the dataset has a small number of missing data\n",
    "2. replace missing data with other values, such as the mean or the most frequent value\n",
    "3. leave missing data as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0730081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0      Aus  44.0  72000.0       Yes\n",
      "1      Aus  27.0  48000.0       Yes\n",
      "2      NaN  30.0  54000.0       NaN\n",
      "3      Aus  38.0  61000.0        No\n",
      "4      Aus  40.0  48000.0       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6   France  27.0  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faculty-34\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "df.iloc[:,1:3]=imputer.fit_transform(df.iloc[:,1:3].values)\n",
    "#df=imputer.fit_transform(df.values)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68e2c1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Aus' 44.0 72000.0 'Yes']\n",
      " ['Aus' 27.0 48000.0 'Yes']\n",
      " ['Aus' 30.0 54000.0 'Yes']\n",
      " ['Aus' 38.0 61000.0 'No']\n",
      " ['Aus' 40.0 48000.0 'Yes']\n",
      " ['France' 35.0 58000.0 'Yes']\n",
      " ['France' 27.0 52000.0 'No']\n",
      " ['France' 48.0 79000.0 'Yes']\n",
      " ['Germany' 50.0 83000.0 'No']\n",
      " ['France' 37.0 67000.0 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "#df.iloc[:,1:3]=imputer.fit_transform(df.iloc[:,1:3].values)\n",
    "df=imputer.fit_transform(df.values)\n",
    "print(df)\n",
    "#print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null Values Handling - Categorical\n",
    "We have already seen how we can handle the numerical data with the help of scikit-learn.\n",
    "In the case of Categorical Data things are a little different because we can't use mean,\n",
    "median. So we basically need to choose the most frequent(mode) for filling up the null\n",
    "values in the case of Categorical data.\n",
    "\n",
    "Let us import pandas and read the csv file initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8864f186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0      Aus  44.0  72000.0       Yes\n",
      "1      Aus  27.0  48000.0       Yes\n",
      "2      NaN  30.0  54000.0       NaN\n",
      "3      Aus  38.0  61000.0        No\n",
      "4      Aus  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6   France   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df=pd.read_csv(\"C:/Users/Faculty-34/Desktop/Data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a58d8f",
   "metadata": {},
   "source": [
    "So this instead of using iloc and selecting only the numeric columns we will be selecting all the columns.\n",
    "We will be using most frequent as the strategy parameter because we cannot use mean and median for categorical datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1951edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "df.iloc[:,:]=imputer.fit_transform(df.iloc[:,:].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b706c1",
   "metadata": {},
   "source": [
    "Now if we print the DataFrame(df) we will notice that the null values of the categorical\n",
    "column as well as the numeric column has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf72dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0       Yes\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2   France  30.0  54000.0       Yes\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0  48000.0       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain  27.0  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3415e8a",
   "metadata": {},
   "source": [
    "To confirm it we can use the isnull().sum() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a1027f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country      0\n",
      "Age          0\n",
      "Salary       0\n",
      "Purchased    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede0317",
   "metadata": {},
   "source": [
    "So we have removed all the null values and replaced them with the most frequent value of that particular column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b9d5f",
   "metadata": {},
   "source": [
    "Null Values Handling on GooglePlaystore Dataset\n",
    "\n",
    "Now we have already seen how we can handle null values for both Numeric and Categorical Data.\n",
    "Let use use those techniques and handle the null values for our GooglePlaystore Dataset.\n",
    "\n",
    "So let us see our dataset again before getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3aa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df=pd.read_csv(\"googleplaystore.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12edc4",
   "metadata": {},
   "source": [
    "Let us use the isnull().sum() function to check the number of null data in every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee78a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa8916",
   "metadata": {},
   "source": [
    "So we have a huge number of data which is null in the Rating column.\n",
    "We can drop the rows which are null but that would not be optimal because\n",
    "the number of data. is very much. So we are going to use the SimpleImputer\n",
    "and replace the null values with the mean of the Rating column.\n",
    "\n",
    "Let's get started with the coding implementation now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute = SimpleImputer(missing_values = np.nan , strategy = 'mean')\n",
    "df.iloc[ : , 2:3 ] =impute.fit_transform(df.iloc[ : , 2:3 ].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9fa5f",
   "metadata": {},
   "source": [
    "So we have replaced the null values with the mean value for the Rating column\n",
    "and there is no loss of data as well. Let us use the isnull().sum() function\n",
    "to again check our null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e602a0e5",
   "metadata": {},
   "source": [
    "So now we have some more null values present in the other columns.\n",
    "So we can see they are very less as compared to the size of the dataset\n",
    "( less than 1%) so we can just remove those null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94e019",
   "metadata": {},
   "source": [
    "So we have removed the rest of the null values and we have no null values present in our dataset anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e70c2b",
   "metadata": {},
   "source": [
    "Data Analysis with Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa11a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "\n",
    "impute = SimpleImputer(missing_values = np.nan , strategy = 'mean')\n",
    "impute.fit(df.iloc[ : , 2:3 ].values)\n",
    "df.iloc[ : , 2:3 ] = impute.transform(df.iloc[ : , 2:3 ].values)\n",
    "\n",
    "df = df.dropna()\n",
    "print(df)\n",
    "df.head()\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. How many free apps are there in ART_AND_DESIGN?\n",
    "\n",
    "df = df.values\n",
    "c = 0\n",
    "\n",
    "for i in df:\n",
    "    if(i[1] == 'ART_AND_DESIGN' and i[6] == 'Free'):\n",
    "        c += 1\n",
    "        \n",
    "print(\"There are\",c,'free apps from ART_AND_DESIGN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. How many apps are there in ART_AND_DESIGN with rating more then 4.5?\n",
    "c = 0\n",
    "\n",
    "for i in df:\n",
    "    if(i[1] == 'ART_AND_DESIGN' and i[2] > 4.5):\n",
    "        c += 1\n",
    "        \n",
    "print(\"There are\",c,'apps from ART_AND_DESIGN with rating more than 4.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618dff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How many apps are there in FAMILY with rating more then 4.5 and Free?\n",
    "c = 0\n",
    "\n",
    "for i in df:\n",
    "    if(i[1] == 'ART_AND_DESIGN' and i[2] > 4.5 and i[6] == 'Free'):\n",
    "        c += 1\n",
    "        \n",
    "print(\"There are\",c,'free apps from ART_AND_DESIGN with rating more than 4.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. List all the free apps with rating more then 4.5 and category is FAMILY?\n",
    "print(\"*\"*100)\n",
    "print(\"        These are the free apps where Category is FAMILY with rating more than 4.5.     \")\n",
    "print(\"*\"*100)\n",
    "\n",
    "for i in df:\n",
    "    if(i[1] == 'ART_AND_DESIGN' and i[2] > 4.5 and i[6] == 'Free'):\n",
    "        print(i[0])\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e00f9",
   "metadata": {},
   "source": [
    "Data Analysis using conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f55c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "\n",
    "impute = SimpleImputer(missing_values = np.nan , strategy = 'mean')\n",
    "impute.fit(df.iloc[ : , 2:3 ].values)\n",
    "df.iloc[ : , 2:3 ] = impute.transform(df.iloc[ : , 2:3 ].values)\n",
    "\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a154344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. How many free apps are there in ART_AND_DESIGN?\n",
    "df_pr = df[df['Category'] == 'ART_AND_DESIGN']\n",
    "print(len(df_pr[df_pr['Type'] == 'Free']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. How many apps are there in ART_AND_DESIGN with rating more then 4.5?\n",
    "df_pr = df[df['Category'] == 'ART_AND_DESIGN']\n",
    "print(len(df_pr[df_pr['Rating'] > 4.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How many apps are there in FAMILY with rating more then 4.5 and Free?\n",
    "df_pr = df[df['Category'] == 'FAMILY']\n",
    "df_pr = df_pr[df_pr['Rating'] > 4.5]\n",
    "len(df_pr[df_pr['Type'] == 'Free'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. List all the free apps with rating more then 4.5 and category is FAMILY?\n",
    "df_pr = df[df['Category'] == 'FAMILY']\n",
    "df_pr = df_pr[df_pr['Rating'] > 4.5]\n",
    "df_pr[df_pr['Type'] == 'Free']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7734de9",
   "metadata": {},
   "source": [
    "Group by in Pandas:\n",
    "Pandas dataframe.groupby() function is used to split the data into groups based on some criteria.\n",
    "Pandas objects can be split on any of their axes.\n",
    "The abstract definition of grouping is to provide a mapping of labels to group names.\n",
    "\n",
    "Syntax:\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a124312",
   "metadata": {},
   "source": [
    "Parameters :\n",
    "    \n",
    "by : mapping, function, str, or iterable\n",
    "    \n",
    "axis : int, default 0\n",
    "    \n",
    "level : If the axis is a MultiIndex (hierarchical), group by a particular level or levels\n",
    "    \n",
    "as_index : For aggregated output, return object with group labels as the index.\n",
    "Only relevant for DataFrame input. as_index=False is effectively “SQL-style” grouped output\n",
    "\n",
    "sort : Sort group keys. Get better performance by turning this off. Note this does not\n",
    "influence the order of observations within each group. groupby preserves the order of rows within each group.\n",
    "\n",
    "group_keys : When calling apply, add group keys to index to identify pieces\n",
    "    \n",
    "squeeze : Reduce the dimensionality of the return type if possible, otherwise return a consistent type\n",
    "\n",
    "Returns : GroupBy object\n",
    "\n",
    "**kwargs allows us to pass a variable number of keyword arguments to a Python function. In the function, we use the double-asterisk ( ** ) before the parameter name to denote this type of argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af628e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad627b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Faculty-34/Desktop/googleplaystore.csv\")\n",
    "impute = SimpleImputer(missing_values = np.nan , strategy = 'mean')\n",
    "impute.fit(df.iloc[ : , 2:3 ].values)\n",
    "df.iloc[ : , 2:3 ] = impute.transform(df.iloc[ : , 2:3 ].values)\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Name the apps that are in ART_AND_DESIGN with rating more then 4.5 in descending order WRT Ratings?\n",
    "df_pr = df[df['Category'] == 'ART_AND_DESIGN']\n",
    "df_pr = df_pr[df_pr['Rating'] > 4.5]\n",
    "\n",
    "df_pr.sort_values( by = 'Rating', ascending = True ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fdea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Which category is having maximum average rating Descending order?\n",
    "df.groupby('Category').mean()['Rating'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How many paid apps are there in each category in Descending Order?\n",
    "df_pr = df[df['Type'] == 'Paid']\n",
    "\n",
    "df_pr.groupby('Category').count()['Type'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15138acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
